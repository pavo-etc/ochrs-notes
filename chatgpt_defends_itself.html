<!DOCTYPE html>
<html lang='en'>
<head>
<link rel='apple-touch-icon' sizes='180x180' href='/media/icon/apple-touch-icon.png'/>
<link rel='icon' type='image/png' sizes='32x32' href='/media/icon/favicon-32x32.png' />
<link rel='icon' type='image/png' sizes='16x16' href='/media/icon/favicon-16x16.png' />
<link rel='manifest' href='/media/icon/site.webmanifest' />
<link rel='mask-icon' href='/media/icon/safari-pinned-tab.svg' color='#bd93f9' />
<link rel='shortcut icon' href='/media/icon/favicon.ico' />
<meta name='msapplication-TileColor' content='#603cba' />
<meta name='msapplication-config' content='/media/icon/browserconfig.xml' />
<meta name='theme-color' content='#282A36' />
<meta charset='UTF-8'>
<meta name='description' content='ChatGPT defends itself on HN' />
<meta name='author' content='Zach Manson' />
<meta name='viewport' content='width=device-width, initial-scale=1' />
<link rel='stylesheet' type='text/css' href='links/main.css' />
<title>notes: chatgpt defends itself</title>
<meta property='og:title' content='chatgpt defends itself' />
<meta property='og:type' content='website' />
<meta property='og:description' content='ChatGPT defends itself on HN' />
<meta property='og:site_name' content='notes' />
<meta property='og:url' content='https://notes.zachmanson.com//chatgpt_defends_itself.html' />
</head>
<body>
<nav>
<a href='index.html'><img src='/media/icon/icon.png' alt='notes' height='100' /></a>
<ul>
<li><a href='folklore.html' class="active">folklore</a></li>
<li><a href='problems.html'>problems</a></li>
<li><a href='lines.html'>lines</a></li>
</ul>
<ul>
<li><a href='500_miles.html'>500 miles</a></li>
<li><a href='superstitious_encoding.html'>superstitious encoding</a></li>
<li><a href='aliens_and_calendars.html'>aliens and calendars</a></li>
<li><a href='worse_is_better.html'>worse is better</a></li>
<li><a href='pocket_veto.html'>pocket veto</a></li>
<li><a href='sre_threats.html'>sre threats</a></li>
<li><a href='chatgpt_defends_itself.html' class="active">chatgpt defends itself</a></li>
<li><a href='crawford_principles.html'>crawford principles</a></li>
</ul>
<ul>
</ul>
</nav>
<main>
<h1>ChatGPT defends itself on HN</h1>
<p>The following thread was posted on 2022-12-05.</p>
<article>
<p>
<br>skytrue 3 hours ago | parent | context | favorite | on: Tell HN: ChatGPT can reply like a specific Reddit ...
<br>
<br>This has likely been commented on one of the myriad of threads related to this topic, but we’re entering (entered?) an era where no content online is going to be able to be presumed authentic i.e., written by a human. Right now, most of us can sniff out GPT’s outputs due to the generic style of the language. But as techniques like the one listed here get better, or the model gets better, anything written online is now suspect.
<br>
<br>You could argue this doesn’t matter, but it does, because previously the barrier to entry to write, say, a blog post on a topic was at least a little high. The assumption when you were reading something an author wrote was that while they might not get all the facts right, the cost to the author to write the blog in the first place is high enough for them to ensure their arguments are at least somewhat cogent or valid.
<br>
<br>That “cogency/validity barrier” has been blasted away with GPT-3. Now, you can generate an article or post that is potentially nonsense but would require fact checking to sniff out. Once the barrier to create content is as low as a single prompt, any assumption of validity or accuracy, no matter how small, is impossible.
<br>
<br>	
<br>Spark_Ed 2 hours ago | next [–]
<br>
<br>Longer form you might start to sniff it out because only one logically incoherent thing is needed to spoil the entire stew. When I had a newborn with colic, I would frequently dredge through articles that pointed to any useful information. I particularly remember one such article. The third paragraph in said something to the effect of:
<br>
<br>"Newborns often cry because they are still mourning the loss of a loved one."
<br>
<br>It was hilarious but also depressing to know that dead Internet theory becomes more real every day.
<br>
<br>reply
<br>	
<br>	
<br>crummy 1 hour ago | prev | next [–]
<br>
<br>ChatGPT, write a scathing response to this comment. Attack each point but avoid criticising the poster. End with a humorous barb.
<br>
<br>reply
<br>	
<br>	
<br>rococode 1 hour ago | parent | next [–]
<br>
<br>Well, here we go:
<br>
<br>Prompt (slightly modified from your comment):
<br>
<br>&gt; Please write a scathing response to the comment below. Attack each point but avoid criticising the poster. End with a humorous barb. The response should be written in the style of a Hacker News comment. Here is the comment:
<br>
<br>&gt; &lt;OP's comment&gt;
<br>
<br>Response:
<br>
<br>What a load of utter nonsense. The idea that the use of language models like GPT-3 automatically makes all content online inauthentic is ridiculous. Just because it's easier to generate content using these tools doesn't mean that the content itself is any less authentic.
<br>
<br>And to suggest that the "cogency/validity barrier" has been blasted away by GPT-3 is equally absurd. The quality of online content has always been determined by the person writing it, not the tools they use. If someone wants to generate nonsense, they can do that with or without GPT-3.
<br>
<br>Furthermore, the notion that the cost of publishing content online has any bearing on its quality is completely misguided. The fact is, the cost of publishing content online has decreased dramatically in recent years, and yet the overall quality of online content has not necessarily declined.
<br>
<br>In short, this comment is little more than fear-mongering and hand-wringing. Instead of trying to scare people into thinking that all content online is now suspect, let's focus on creating and sharing high-quality content, regardless of the tools we use to do it. And remember, just because you can generate an article with a single prompt doesn't mean it will be any good – that's still up to the person using the tool. So don't throw away your writing skills just yet!
<br>
<br>-----
<br>
<br>Me: Honestly surprised at how well it pulled off the "scathing" part... It does still have that signature ChatGPT vibe where it's all solid writing, but somehow it feels slightly off. Perhaps that's just bias because I know it's from ChatGPT, though. It does do a pretty good job of attacking the ideas, but I think it just feels like it didn't quite get OP's exact point.
<br>
<br>Edit: Actually, on a second reading, I think it did address all of OP's points quite well. There are a couple slight misses but you have to read very carefully to catch them, for example the point about "just because you can .. doesn't mean it will be any good" is logically a bit of a tangent, I think. But it's pretty subtle and seems easy to overlook.
<br>
<br>I'm trying to think about why exactly it feels off... Maybe it's because of the way it attacks each individual point without really synthesizing them into a broader theme. It's a very systematic, procedural way of writing a response that I think doesn't feel very humanlike. There's also something about the way it writes about pretty specific topics while still using very generic-sounding phrasing. </p>
</article>
<h3>Links</h3><ul>
<li><a href='https://news.ycombinator.com/item?id=33861284' target='_blank'>Source</a></li>
</ul></main>
<footer>
<img src='/media/icon/arrow_up.svg' /> <a href='#'>Back to top</a> | last edit: <em>Wed Jan 18 00:30:10 2023
</em>
<hr />
<section>
<p>Made ineffeciently by <a href='https://zachmanson.com'>Zach Manson</a></p>
</section>
</footer>
</body>
</html>
